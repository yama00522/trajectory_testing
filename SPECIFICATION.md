# trajectory_testing - パイプライン仕様書

## プロジェクト概要

このプロジェクトは、定期的にCSVファイルを生成し、複数のCSVファイルをマージして履歴を保持するシステムです。
リアルタイムデータストリームのシミュレーションと、スライディングウィンドウ方式のマージ処理を実装しています。

---

## システムアーキテクチャ

```
CsvCreator（無効化）
    ↓ [生成間隔: 1秒]
output_csv/ [最新データ格納]
    ↓
CsvMerger [常時監視]
    ├→ merged_csv/ [全マージ結果を履歴保持]
    └→ merged_outdate/ [最新マージ結果（上書き）]
```

---

## 各モジュールの詳細

### 1. CsvCreator（`csv_creator.py`）

#### 目的
1秒ごとにタイムスタンプ付きのCSVファイルを生成します。

#### 主要メソッド

**`__init__(output_dir, interval_sec=1)`**
- `output_dir`: CSVファイルの出力ディレクトリ
- `interval_sec`: ファイル生成の間隔（デフォルト: 1秒）
- 出力ディレクトリが存在しない場合は自動作成

**`_sleep_until_next_tick()`**
- 次の実行タイミングまで正確に待機
- マイクロ秒単位の調整で、1秒ごとの厳密な実行を実現

**`_create_csv()`**
- タイムスタンプ形式: `YYYYMMDD_HHMMSS`
- ファイル名例: `20260104_125930.csv`
- ファイル内容:
  ```
  column1,column2
  20260104_125930_1_1,20260104_125930_1_2
  20260104_125930_2_1,20260104_125930_2_2
  20260104_125930_3_1,20260104_125930_3_2
  ```

**`run()`**
- 無限ループでファイル生成を継続

#### 処理フロー

```
初期化
  ↓
次の実行タイミングを計算（マイクロ秒精度）
  ↓
[無限ループ]
  ├→ 次の実行タイミングまで待機
  ├→ タイムスタンプ付きCSVを生成
  ├→ 出力ディレクトリに保存
  └→ 次の実行タイミングを更新
```

---

### 2. CsvMerger（`csv_merger.py`）

#### 目的
複数の最新CSVファイルをマージして、以下の2つの出力を生成します：
- **履歴保持版**: 毎回の実行結果を新ファイルで保存（`merged_YYYYMMDD_HHMMSS.csv`）
- **最新版**: 最新のマージ結果を常に上書き（`merged_outdate.csv`）

#### 主要メソッド

**`__init__(input_dir, output_dir, outdate_dir, num_files=20, interval_sec=1)`**
- `input_dir`: 監視対象のCSVファイルディレクトリ（`./output_csv`）
- `output_dir`: マージ結果の履歴保持先（`./merged_csv`）
- `outdate_dir`: 最新マージ結果の上書き保存先（`./merged_outdate`）
- `num_files`: マージする直近ファイル数（デフォルト: 20）
- `interval_sec`: マージ実行間隔（デフォルト: 1秒）

**`_sleep_until_next_tick()`**
- CsvCreator と同じ タイミング調整機構
- 1秒ごとの厳密な実行を実現

**`_merge_csvs()`**
マージ処理の詳細：

1. **入力ファイル収集**
   - `input_dir` 内の全CSVファイルを取得
   - アルファベット順でソート
   - 最新の `num_files` 個を対象に選定

2. **ヘッダー処理**
   - 最初のファイルからヘッダー行を抽出
   - 全出力ファイルの先頭に1回だけ記述

3. **行統合**
   - 各ファイルのデータ行をすべて連結
   - ヘッダー行の重複は自動削除

4. **ファイル出力**
   - **履歴版**: `merged_YYYYMMDD_HHMMSS.csv` として新規保存
   - **最新版**: 一時ファイル経由で `merged_outdate.csv` に原子的に置換
     - Windows/Linux 両環境で安全な上書きを実現
     - 不完全な上書きを防止

5. **出力例**
   ```
   column1,column2
   20260104_125930_1_1,20260104_125930_1_2
   20260104_125930_2_1,20260104_125930_2_2
   20260104_125930_3_1,20260104_125930_3_2
   20260104_125931_1_1,20260104_125931_1_2
   20260104_125931_2_1,20260104_125931_2_2
   20260104_125931_3_1,20260104_125931_3_2
   ...（最新20ファイル分）
   ```

**`run()`**
- 無限ループでマージ処理を継続

#### 処理フロー

```
初期化
  ├→ 出力ディレクトリを作成
  └→ 次の実行タイミングを計算

[無限ループ]
  ├→ 次の実行タイミングまで待機
  ├→ input_dir から全CSVを取得
  ├→ 最新 num_files 個を抽出
  ├→ マージ処理
  │   ├→ ヘッダー統合
  │   └→ 全行統合
  ├→ 履歴版を新規保存（merged_YYYYMMDD_HHMMSS.csv）
  ├→ 最新版を原子的に置換（merged_outdate.csv）
  └→ 次の実行タイミングを更新
```

---

### 3. パイプラインメインスクリプト（`run_pipeline.py`）

#### 目的
複数のモジュールを並行処理として起動・管理します。

#### 処理内容

```python
# 現在の実装
merger = CsvMerger(
    input_dir="./output_csv",
    output_dir="./merged_csv",
    outdate_dir="./merged_outdate",
    num_files=20,
)

Thread(target=merger.run, daemon=True).start()

while True:
    pass
```

#### 起動モジュール
- **CsvCreator**: コメント化（無効）
- **CsvMerger**: デーモンスレッドで起動

#### 実行フロー

```
main() 開始
  ├→ CsvMerger をインスタンス化
  ├→ デーモンスレッドで merger.run() を開始
  └→ メインスレッドは無限ループで待機
```

---

## ディレクトリ構造と役割

```
trajectory_testing/
├── run_pipeline.py          # メインパイプライン
├── csv_creator.py           # ファイル生成モジュール（現在無効）
├── csv_merger.py            # ファイルマージモジュール
├── requirements.txt         # Python依存パッケージ（なし）
├── Dockerfile               # Docker イメージ定義
├── docker-compose.yml       # Docker Compose 設定
├── output_csv/              # 入力ファイル格納先（CsvCreator が生成）
├── merged_csv/              # マージ結果の履歴保持（時系列で複数ファイル）
└── merged_outdate/          # マージ結果の最新版（常に1ファイル）
    └── merged_outdate.csv   # 最新マージ結果
```

---

## タイミング制御の詳細

### スケジュール同期

両モジュールはマイクロ秒精度のタイミング調整を実装：

```python
def _sleep_until_next_tick(self) -> None:
    sleep_time: float = (self.next_tick - datetime.now()).total_seconds()
    if sleep_time > 0:
        time.sleep(sleep_time)
```

- **目標**: 各スレッドが毎秒の同じタイミングで実行
- **精度**: マイクロ秒単位の調整
- **利点**: 同期性が取れた負荷分散が可能

### 実行タイミング例

```
時刻          CsvCreator              CsvMerger
12:59:30     ファイル生成完了          ↓（前回のマージ結果を利用）
12:59:31     ↓（新ファイル生成待中）    マージ処理 → 履歴 + 最新版 更新
12:59:32     ファイル生成完了          ↓（最新20ファイルをマージ）
12:59:33     ↓                        マージ処理
```

---

## データフロー例

### シナリオ: 20ファイルマージの実行

**入力ファイル**: `output_csv/` に以下が存在
```
20260104_125930.csv
20260104_125931.csv
...
20260104_125949.csv  ← 最新ファイル（これから20個前まで対象）
```

**処理結果**:

1. **履歴版** (`merged_csv/`)
   ```
   merged_20260104_125930.csv  ← 1回目の実行結果
   merged_20260104_125931.csv  ← 2回目の実行結果
   merged_20260104_125932.csv  ← 3回目の実行結果
   ...
   ```

2. **最新版** (`merged_outdate/merged_outdate.csv`)
   ```
   最新のマージ結果を常に保持（上書き）
   ```

---

## 主要な特性

| 項目 | 説明 |
|------|------|
| **生成速度** | 1秒ごと（1行あたり3列の2行データ） |
| **マージ対象** | 直近20ファイル（約20秒分のデータ） |
| **出力方式** | 履歴保持 + 最新版上書き |
| **スレッド** | デーモンスレッドで非ブロッキング実行 |
| **精度** | マイクロ秒単位のタイミング同期 |
| **安全性** | 一時ファイル経由による原子的更新（Windows/Linux対応） |

---

## Docker化のメリット

このスクリプトをDocker化することで以下が実現：

- **環境の一貫性**: Python 3.11 環境を固定
- **ポータビリティ**: 任意の Linux/Windows マシンで同じ動作
- **ボリュームマウント**: ホスト側でファイルを直接確認可能
- **スケーラビリティ**: 複数コンテナの並列実行が容易

---

## 今後の拡張案

1. **CsvCreator の有効化**: 実際のデータソースから読み込み
2. **外部データソース対応**: API/データベースからのデータ取得
3. **フィルタリング機能**: 条件に基づくマージデータの選別
4. **エクスポート機能**: マージ結果を別形式（JSON、Parquet等）で出力
5. **エラーハンドリング**: 例外発生時の復旧機構
6. **ログ記録**: 処理結果の詳細ログ保存


## 補足(外部スクリプトの読み取り例)
外部スクリプトの読み取り例（安全）
from pathlib import Path
import csv
outdir = Path("./merged_csv")
latest_name = (outdir / "latest.txt").read_text().strip()
with open(outdir / latest_name, encoding="utf-8") as f:
    rows = list(csv.reader(f))
print(rows)